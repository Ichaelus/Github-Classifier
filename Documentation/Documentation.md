# Documentation

"Please also document the decisions you made selecting your features, 
algorithms, data structures and software development tools and practices."

## Inital Approach/Planning Phase 

### Our Strategy to get our train data
* Api-Call Limit, erste Website

### First Data Set Impressions
* Erste Versuche mit ersten Classifiern/Entdecken des Majority Class Problems
* Erste Überlegungen zu den Features
### Discussions about Class Descriptions
Unklare Klassenbeschreibungen

## Software Architecture

### Goals
* MainlyReusability, make it as easy as possible to try and compare different solutions etc
Possibily also for other projects
### Overview
### Python application
### Webserver

## Data Exploration and Prediction Model
### Features
* hier kommen unsere Überlegungen zu den Features rein

### Prediction Model
* hier kommen unsere Überlegungen zu den Classifiern rein

### Example Repositories
"Please document three repositories where you assume that your 
application will yield better results as compared to the results of other teams."

## Validation
"Apply your classifier on the repositories included in  Appendix B . 
You can find this file on https://github.com/InformatiCup/InformatiCup2017 as well. 
Create a boolean matrix where you compare the results where you compare the results of your 
classifier and your intuitive classification (if your intuitive classification matches the output 
of your program, the element in the matrix will result to true, otherwise to false).
Compute the recall per category- the number of repositories intuitively placed within a 
category in the set of repositories that got placed in the same category by your classifier.
Compute the  precision per category- the number of repositories per category where the results 
determined by your automatic classifier matched your intuitive classification.
Discuss the quality of your results and argue whether, according to your opinion, 
a higher yield or a higher precision is more important for automated repository classification."
